robot = "acrobot"
reward_type = "quadratic"
Q[0, 0] = 10
Q[1, 1] = 10
Q[2, 2] = 0.4
Q[3, 3] = 0.3
R = np.array([[0.0001]])
n_envs = 50

# tuning parameters
training_steps = 1e6
log_dir = "sac_training"
verbose = 1
reward_threshold = -0.01
eval_freq=5000
n_eval_episodes=2
learning_rate=0.01

control_line = 0.4
reward = -r + 40

if max_diff > 0.3:
    bonus = False
else:
    bonus = True
    reward += (1 - max_diff) * 100