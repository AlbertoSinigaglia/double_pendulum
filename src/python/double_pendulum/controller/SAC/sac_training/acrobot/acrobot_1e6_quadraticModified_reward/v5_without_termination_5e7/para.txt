robot = "acrobot"
reward_type = "quadratic"
Q[0, 0] = 10
Q[1, 1] = 10
Q[2, 2] = 0.4
Q[3, 3] = 0.3
R = np.array([[0.0001]])
n_envs = 50

# tuning parameters
n_envs = 50
training_steps = 5e7
log_dir = "sac_training"
verbose = 1
# reward_threshold = -0.01
reward_threshold = 1e6
eval_freq=5000
n_eval_episodes=2
learning_rate=0.01

control_line = 0.4
reward1 = -r
reward2 = 100
# roa
reward3 = 1e3

check_if_state_in_roa(S,rho,x)